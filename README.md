# Proyecto de Entrenamiento de Modelo XGBoost con OptimizaciÃ³n de HiperparÃ¡metros

Este proyecto tiene como objetivo entrenar un modelo de XGBoost utilizando datos de sensores (velocidad, presiÃ³n, etc.), optimizar los hiperparÃ¡metros mediante RandomizedSearchCV y evaluar su rendimiento tanto antes como despuÃ©s de la optimizaciÃ³n. AdemÃ¡s, se guardarÃ¡ y cargarÃ¡ el modelo para su reutilizaciÃ³n en futuras predicciones.

## Contenido
- [Requisitos](#requisitos)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Instrucciones de EjecuciÃ³n](#instrucciones-de-ejecuciÃ³n)
- [EvaluaciÃ³n y Resultados](#evaluaciÃ³n-y-resultados)
  - [Entrenamiento Inicial](#entrenamiento-inicial)
  - [OptimizaciÃ³n de HiperparÃ¡metros](#optimizaciÃ³n-de-hiperparÃ¡metros)
  - [Modelo Cargado](#modelo-cargado)
- [ImÃ¡genes](#imÃ¡genes)

## Requisitos

Para ejecutar este proyecto de manera local, asegÃºrate de tener instalados los siguientes paquetes:

- pandas
- xgboost
- scikit-learn
- joblib
- matplotlib
- numpy
- boto3 (si deseas trabajar con S3)

Puedes instalar las dependencias necesarias utilizando pip:

```bash
pip install pandas xgboost scikit-learn joblib matplotlib numpy boto3


ğŸ“¦ Proyecto_XGBoost
 â”£ ğŸ“‚ data
 â”ƒ â”£ ğŸ“œ xgboost_ready_data_month.csv      # Dataset con el que se entrena el modelo
 â”£ ğŸ“‚ images                             # Carpeta para las imÃ¡genes de grÃ¡ficos generados
 â”ƒ â”£ ğŸ“œ entrenamiento1.png               # GrÃ¡fico predicciones vs reales, sin optimizaciÃ³n
 â”ƒ â”£ ğŸ“œ entrenamiento2hiperparametros.png # GrÃ¡fico predicciones vs reales, optimizado
 â”ƒ â”£ ğŸ“œ modelocargado3.png                # GrÃ¡fico predicciones vs reales, modelo cargado
 â”£ ğŸ“œ 1_cargar_datos.py                   # Script para cargar y dividir los datos
 â”£ ğŸ“œ 2_entrenar_modelo.py                # Script para entrenar el modelo sin optimizaciÃ³n
 â”£ ğŸ“œ 3_optimizar_modelo.py               # Script para optimizar el modelo con RandomizedSearchCV
 â”£ ğŸ“œ 4_cargar_modelo.py                  # Script para cargar el modelo guardado y evaluar
 â”£ ğŸ“œ README.md                           # Este archivo README
 â”— ğŸ“œ requirements.txt                    # Archivo con las dependencias necesarias
# Instrucciones de EjecuciÃ³n
# Cargar y Dividir Datos

El primer paso es cargar los datos desde el archivo CSV y dividirlos en conjuntos de entrenamiento y prueba. El cÃ³digo se encuentra en 1_cargar_datos.py.

bash
Copiar cÃ³digo
python 1_cargar_datos.py
Los datos se dividen en un 80% para entrenamiento y un 20% para prueba. Se generarÃ¡ la siguiente salida con la cantidad de muestras en cada conjunto:

yaml
Copiar cÃ³digo
Conjunto de entrenamiento: (69096, 6), Conjunto de prueba: (17275, 6)
# Entrenamiento del Modelo BÃ¡sico

En el archivo 2_entrenar_modelo.py se entrena un modelo bÃ¡sico de XGBoost sin optimizaciÃ³n de hiperparÃ¡metros.

bash
Copiar cÃ³digo
python 2_entrenar_modelo.py
DespuÃ©s de entrenar el modelo, se genera un grÃ¡fico con las predicciones versus los valores reales.

GrÃ¡fico de entrenamiento bÃ¡sico (sin optimizaciÃ³n):
# OptimizaciÃ³n de HiperparÃ¡metros

El archivo 3_optimizar_modelo.py contiene la implementaciÃ³n de RandomizedSearchCV para encontrar los mejores hiperparÃ¡metros del modelo.

bash
Copiar cÃ³digo
python 3_optimizar_modelo.py
DespuÃ©s de la optimizaciÃ³n, se muestra el siguiente grÃ¡fico con las predicciones optimizadas.

GrÃ¡fico de optimizaciÃ³n con hiperparÃ¡metros:
# Guardar y Cargar el Modelo

El modelo optimizado se guarda en un archivo .pkl para su posterior uso. Luego, puedes cargar este modelo utilizando el archivo 4_cargar_modelo.py.

bash
Copiar cÃ³digo
python 4_cargar_modelo.py
Este script cargarÃ¡ el modelo guardado y evaluarÃ¡ su rendimiento nuevamente. Se generarÃ¡ el siguiente grÃ¡fico:

GrÃ¡fico de predicciones con el modelo cargado:
# EvaluaciÃ³n y Resultados
# Entrenamiento Inicial
DespuÃ©s de entrenar el modelo sin optimizaciÃ³n de hiperparÃ¡metros, los resultados iniciales son los siguientes:

bash
Copiar cÃ³digo
MSE: 719.471593554146
RÂ²: 0.8039996548861984
GrÃ¡fico:
# OptimizaciÃ³n de HiperparÃ¡metros
Utilizando RandomizedSearchCV, los mejores hiperparÃ¡metros encontrados fueron:

bash
Copiar cÃ³digo
Mejores hiperparÃ¡metros: {'subsample': 0.9, 'reg_lambda': 1.0, 'reg_alpha': 0.0001, 'n_estimators': 500, 'max_depth': 11, 'learning_rate': 0.08944444444444445, 'gamma': 0.5, 'colsample_bytree': 1.0}
Los resultados despuÃ©s de la optimizaciÃ³n son:

bash
Copiar cÃ³digo
MSE optimizado: 217.73657880850624
RÂ² optimizado: 0.9406836281338827
GrÃ¡fico:
# Modelo Cargado
Finalmente, al cargar el modelo optimizado y evaluarlo nuevamente, obtenemos los mismos resultados:

bash
Copiar cÃ³digo
MSE cargado: 217.73657880850624
RÂ² cargado: 0.9406836281338827
GrÃ¡fico:
# ImÃ¡genes